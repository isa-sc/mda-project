{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import re\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from shapely.geometry import MultiPolygon, Point, Polygon\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.metrics import precision_score, accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df =  pd.read_parquet('train_df.parquet.gzip')\n",
    "test_df =  pd.read_parquet('test_df.parquet.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MachineLearning:\n",
    "    def __init__(self, train_dataset, test_dataset, model_type):\n",
    "            self.train_dataset = train_dataset.copy()\n",
    "            self.test_dataset = test_dataset.copy()\n",
    "            self.model_type = model_type\n",
    "            self.scaler_trained = False\n",
    "            self.model_selection()\n",
    "\n",
    "    def cleaning(self, data):\n",
    "        data['time_cleaned'] =   data['time_cleaned'].apply(lambda t: t.hour * 3600 + t.minute * 60 + t.second)\n",
    "        columns_to_drop=['missionid','moment','dataframe','eventleveltype_cleaned',\n",
    "                         'geometry','in_Belgium','AEDneeded_cleaned','day_cleaned']\n",
    "        x_data = data.drop(columns=columns_to_drop)\n",
    "        y_data = data['AEDneeded_cleaned']\n",
    "        return x_data, y_data\n",
    "    \n",
    "    def scaling (self, dataset):\n",
    "        columns_to_scale = ['time_cleaned', 'latitude_cleaned', 'longitude_cleaned']\n",
    "        if self.scaler_trained == False:\n",
    "            self.scaler = StandardScaler()\n",
    "            data_scaled =self.scaler.fit_transform(dataset[columns_to_scale])\n",
    "            self.scaler_trained= True\n",
    "        else:\n",
    "             data_scaled =self.scaler.transform(dataset[columns_to_scale])\n",
    "        columns_to_scaled = ['time_cleaned_s', 'latitude_cleaned_s', 'longitude_cleaned_s']\n",
    "        data_scaled = pd.DataFrame(data_scaled, columns = columns_to_scaled)\n",
    "        data_scaled = pd.concat([data_scaled, dataset], axis = 1)\n",
    "        data_scaled = data_scaled.drop(columns= columns_to_scale)\n",
    "        data_arranged = self.rearrange(data_scaled)\n",
    "        return data_arranged\n",
    "    def preprocessing_choose_model(self):\n",
    "        self.x_train, self.y_train = self.cleaning(self.train_dataset)\n",
    "        self.x_test, self.y_test =self.cleaning(self.test_dataset)\n",
    "        self.x_train_scaled = self.scaling(self.x_train)\n",
    "        self.x_test_scaled = self.scaling(self.x_test)\n",
    "\n",
    "    def model_selection(self):\n",
    "        self.preprocessing_choose_model()\n",
    "        if self.model_type == 'knn':\n",
    "            self.make_knn()\n",
    "            self.best_knn(self.precision_score, 0.9)\n",
    "\n",
    "    def make_knn(self):\n",
    "        n_neighbors = np.arange(2, 30, 3)\n",
    "        weights = ['uniform', 'distance']\n",
    "        self.precision_score = {}\n",
    "        self.accuracy_score = {}\n",
    "        for weight in weights:\n",
    "            for neighbor in n_neighbors:\n",
    "                self.knn = KNeighborsClassifier(n_neighbors=neighbor, weights=weight)\n",
    "                self.knn.fit(self.x_train_scaled, self.y_train)\n",
    "                self.y_pred = self.knn.predict(self.x_test_scaled)\n",
    "                predict_labels = ['Requires AED', 'Maybe requires AED', 'Does not require AED']\n",
    "                self.accuracy_score[(neighbor, weight)] = accuracy_score(self.y_test, self.y_pred)\n",
    "                self.precision_score[(neighbor, weight)] = precision_score(self.y_test, self.y_pred, labels=predict_labels, average=None)\n",
    "\n",
    "    def best_knn(self, precision_score, accuracy_cutoff):\n",
    "        max_value = 0\n",
    "        max_key = ''\n",
    "        for key, item in precision_score.items():\n",
    "            if self.accuracy_score[key]> accuracy_cutoff:\n",
    "                if item[0] > max_value: \n",
    "                    max_value=item[0]\n",
    "                    max_key = key\n",
    "        print(max_key, max_value)\n",
    "        self.optimal_knn= KNeighborsClassifier(n_neighbors=max_key[0], weights=max_key[1])\n",
    "        self.optimal_knn.fit(self.x_train_scaled, self.y_train)\n",
    "        self.optimal_y_pred = self.optimal_knn.predict(self.x_test_scaled)\n",
    "\n",
    "    def predicting(self, df_topredict):\n",
    "        scaled_df_topredict = self.scaling(df_topredict)\n",
    "        predictions = self.optimal_knn.predict(scaled_df_topredict)\n",
    "        predictions = pd.DataFrame(predictions, columns=['predictions'])\n",
    "        return predictions\n",
    "    \n",
    "    def rearrange(self, df_toarrange):\n",
    "        df_arranged =pd.DataFrame()\n",
    "        df_arranged['lat'] = df_toarrange['latitude_cleaned_s']\n",
    "        df_arranged['long'] = df_toarrange['longitude_cleaned_s']\n",
    "        df_arranged['Monday'] = df_toarrange['Monday']\n",
    "        df_arranged['Tuesday'] = df_toarrange['Tuesday']\n",
    "        df_arranged['Wednesday'] = df_toarrange['Wednesday']\n",
    "        df_arranged['Thursday'] = df_toarrange['Thursday']\n",
    "        df_arranged['Friday'] = df_toarrange['Friday']\n",
    "        df_arranged['Saturday'] = df_toarrange['Saturday']\n",
    "        df_arranged['Sunday'] = df_toarrange['Sunday']\n",
    "        df_arranged['Time'] = df_toarrange['time_cleaned_s']\n",
    "        return df_arranged\n",
    "                          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 'distance') 0.9529378324603078\n"
     ]
    }
   ],
   "source": [
    "knn_model = MachineLearning(train_dataset=train_df,\n",
    "                            test_dataset=test_df, model_type='knn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomGenerator:\n",
    "    def __init__(self,municipalities_gdf, region):\n",
    "        self.municipalities_gdf =municipalities_gdf\n",
    "        self.region = region\n",
    "        self.select_region()\n",
    "\n",
    "    def select_region(self):\n",
    "        if self.region == 'Brussels':\n",
    "            self.gdf_Brussels =pd.DataFrame()\n",
    "            brussels_communes= self.municipalities_gdf.loc[self.municipalities_gdf['arrond'] == '21', ['Communes']].values.tolist()\n",
    "            for commune in range(len(brussels_communes)):\n",
    "                self.region = brussels_communes[commune][0]\n",
    "                self.generate_points()\n",
    "                self.select_points_in_region()\n",
    "                print(len(self.final_generated))\n",
    "                self.gdf_Brussels = pd.concat([self.gdf_Brussels,self.final_generated])\n",
    "                print(len(self.gdf_Brussels))\n",
    "            self.final_generated =self.gdf_Brussels\n",
    "        else:\n",
    "            self.generate_points()\n",
    "            self.select_points_in_region()\n",
    "    \n",
    "    def generate_points(self):\n",
    "        self.areas = {'Anderlecht': 17.74,'Oudergem':9.03,'Sint-Agatha-Berchem':2.95, 'Bruxelles':32.61,'Etterbeek':3.15,'Evere': 5.02,'Forest': 6.25, 'Ganshoren': 2.46,\n",
    "         'Ixelles': 6.34,'Jette': 5.04,'Koekelberg': 1.17,'Sint-Jans-Molenbeek': 5.89,'Saint-Gilles':2.52,'Sint-Joost-ten-Node': 1.14,'Schaerbeek': 8.14,\n",
    "         'Uccle': 22.91,'Watermael-Boitsfort':12.93,'Sint-Lambrechts-Woluwe': 7.22,'Sint-Pieters-Woluwe': 8.85,'Antwerpen': 204.51,'Brugge': 138.40,\n",
    "         'Gent': 156.18,'Hasselt': 102.24,'Leuven': 56.63,  'Mons': 146.53,'Li√®ge': 69.39,'Charleroi': 102.08, 'Namur': 175.69, 'Arlon': 118.64}\n",
    "        self.city_polygon = self.municipalities_gdf.loc[self.municipalities_gdf['Communes'] == self.region,'geometry']\n",
    "        scaling_factor = self.areas[self.region]\n",
    "        latitude_generated = np.random.uniform(self.city_polygon.bounds['miny'], self.city_polygon.bounds['maxy'], int(500*scaling_factor))\n",
    "        longitude_generated= np.random.uniform(self.city_polygon.bounds['minx'], self.city_polygon.bounds['maxx'], int(500*scaling_factor))\n",
    "        latitude_generated=pd.DataFrame(latitude_generated, columns=['latitude_cleaned'])\n",
    "        longitude_generated=pd.DataFrame(longitude_generated, columns=['longitude_cleaned'])\n",
    "        self.df_generated = pd.concat([latitude_generated, longitude_generated], axis =1)\n",
    "\n",
    "    def select_points_in_region(self):\n",
    "        self.gdf_generated= gpd.GeoDataFrame(self.df_generated, geometry=gpd.points_from_xy(self.df_generated['longitude_cleaned'], self.df_generated['latitude_cleaned']), crs=\"EPSG:4326\")\n",
    "        self.gdf_generated['in_city'] = self.gdf_generated['geometry'].apply(lambda x: self.city_polygon.contains(x))\n",
    "        self.gdf_generated_city = self.gdf_generated[self.gdf_generated['in_city'] == True]\n",
    "        self.final_generated = self.gdf_generated_city.drop(columns=['geometry', 'in_city']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_municipalities= r'BELGIUM_-_Municipalities.geojson'\n",
    "municipalities_gdf = gpd.read_file(file_path_municipalities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4812\n",
      "4812\n",
      "1598\n",
      "6410\n",
      "796\n",
      "7206\n",
      "4753\n",
      "11959\n",
      "860\n",
      "12819\n",
      "1234\n",
      "14053\n",
      "1462\n",
      "15515\n",
      "665\n",
      "16180\n",
      "1155\n",
      "17335\n",
      "1192\n",
      "18527\n",
      "262\n",
      "18789\n",
      "1258\n",
      "20047\n",
      "663\n",
      "20710\n",
      "242\n",
      "20952\n",
      "2044\n",
      "22996\n",
      "6218\n",
      "29214\n",
      "3201\n",
      "32415\n",
      "1829\n",
      "34244\n",
      "2267\n",
      "36511\n"
     ]
    }
   ],
   "source": [
    "dic_for_cities = {}\n",
    "df_cities = {}\n",
    "cities = ['Brussels', 'Antwerpen', 'Brugge', 'Gent', 'Hasselt', 'Leuven', 'Mons', 'Li√®ge', 'Charleroi', 'Namur', 'Arlon']\n",
    "for city in cities:\n",
    "    df_with_indicators = pd.DataFrame()\n",
    "    columns = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    df_cities[city] = RandomGenerator(municipalities_gdf, city).final_generated\n",
    "    df_indicators = pd.DataFrame(data=0,index=range(len(df_cities[city])), columns=columns)\n",
    "    df_cities[city] =df_cities[city].reset_index(drop=True)\n",
    "    df_with_indicators = pd.concat([df_cities[city], df_indicators], axis = 1)\n",
    "\n",
    "    dic_for_days ={}\n",
    "    days=columns\n",
    "    for day in days:\n",
    "        df_for_this_day = df_with_indicators.copy()\n",
    "        df_for_this_day[day] = 1\n",
    "        dic_for_days[day] = df_for_this_day\n",
    "        for other_day in days:\n",
    "            if other_day != day:\n",
    "                df_for_this_day[other_day] = 0\n",
    "\n",
    "    dic_all_dfs = {}\n",
    "    for day in dic_for_days.keys():\n",
    "        for hour in range(24):\n",
    "            df_for_this_hour = dic_for_days[day].copy()\n",
    "            df_for_this_hour['time_cleaned'] = hour\n",
    "            dic_all_dfs[(day, hour)]=df_for_this_hour\n",
    "\n",
    "    dic_for_cities[city]= dic_all_dfs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = ['Brussels', 'Antwerpen', 'Brugge', 'Gent', 'Hasselt', 'Leuven', 'Mons', 'Li√®ge', 'Charleroi', 'Namur', 'Arlon']\n",
    "days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "all_predictions ={}\n",
    "for city in cities:\n",
    "    predictions_per_city ={}\n",
    "    for day in days:\n",
    "        predictions = pd.DataFrame()\n",
    "        predictions['lat'] = dic_for_cities[city][('Monday',0)]['latitude_cleaned']\n",
    "        predictions['lon'] = dic_for_cities[city][('Monday',0)]['longitude_cleaned']\n",
    "        for hour in range(24):\n",
    "            to_predict = dic_for_cities[city][(day,hour)]\n",
    "            column_name = f'hour_{hour}'\n",
    "            predictions[column_name] = knn_model.predicting(to_predict)\n",
    "        predictions_per_city[day]=predictions\n",
    "    all_predictions[city]=predictions_per_city\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hour_0\n",
      "Does not require AED    15604\n",
      "Name: count, dtype: int64\n",
      "hour_0\n",
      "Does not require AED    29670\n",
      "Requires AED              108\n",
      "Maybe requires AED         32\n",
      "Name: count, dtype: int64\n",
      "hour_1\n",
      "Does not require AED    15604\n",
      "Name: count, dtype: int64\n",
      "hour_1\n",
      "Does not require AED    29670\n",
      "Requires AED              108\n",
      "Maybe requires AED         32\n",
      "Name: count, dtype: int64\n",
      "hour_2\n",
      "Does not require AED    15604\n",
      "Name: count, dtype: int64\n",
      "hour_2\n",
      "Does not require AED    29670\n",
      "Requires AED              108\n",
      "Maybe requires AED         32\n",
      "Name: count, dtype: int64\n",
      "hour_3\n",
      "Does not require AED    15604\n",
      "Name: count, dtype: int64\n",
      "hour_3\n",
      "Does not require AED    29668\n",
      "Requires AED              109\n",
      "Maybe requires AED         33\n",
      "Name: count, dtype: int64\n",
      "hour_4\n",
      "Does not require AED    15604\n",
      "Name: count, dtype: int64\n",
      "hour_4\n",
      "Does not require AED    29665\n",
      "Requires AED              112\n",
      "Maybe requires AED         33\n",
      "Name: count, dtype: int64\n",
      "hour_5\n",
      "Does not require AED    15604\n",
      "Name: count, dtype: int64\n",
      "hour_5\n",
      "Does not require AED    29665\n",
      "Requires AED              112\n",
      "Maybe requires AED         33\n",
      "Name: count, dtype: int64\n",
      "hour_6\n",
      "Does not require AED    15604\n",
      "Name: count, dtype: int64\n",
      "hour_6\n",
      "Does not require AED    29664\n",
      "Requires AED              112\n",
      "Maybe requires AED         34\n",
      "Name: count, dtype: int64\n",
      "hour_7\n",
      "Does not require AED    15604\n",
      "Name: count, dtype: int64\n",
      "hour_7\n",
      "Does not require AED    29662\n",
      "Requires AED              114\n",
      "Maybe requires AED         34\n",
      "Name: count, dtype: int64\n",
      "hour_8\n",
      "Does not require AED    15604\n",
      "Name: count, dtype: int64\n",
      "hour_8\n",
      "Does not require AED    29661\n",
      "Requires AED              115\n",
      "Maybe requires AED         34\n",
      "Name: count, dtype: int64\n",
      "hour_9\n",
      "Does not require AED    15604\n",
      "Name: count, dtype: int64\n",
      "hour_9\n",
      "Does not require AED    29661\n",
      "Requires AED              115\n",
      "Maybe requires AED         34\n",
      "Name: count, dtype: int64\n",
      "hour_10\n",
      "Does not require AED    15604\n",
      "Name: count, dtype: int64\n",
      "hour_10\n",
      "Does not require AED    29659\n",
      "Requires AED              115\n",
      "Maybe requires AED         36\n",
      "Name: count, dtype: int64\n",
      "hour_11\n",
      "Does not require AED    15604\n",
      "Name: count, dtype: int64\n",
      "hour_11\n",
      "Does not require AED    29658\n",
      "Requires AED              115\n",
      "Maybe requires AED         37\n",
      "Name: count, dtype: int64\n",
      "hour_12\n",
      "Does not require AED    15604\n",
      "Name: count, dtype: int64\n",
      "hour_12\n",
      "Does not require AED    29657\n",
      "Requires AED              116\n",
      "Maybe requires AED         37\n",
      "Name: count, dtype: int64\n",
      "hour_13\n",
      "Does not require AED    15604\n",
      "Name: count, dtype: int64\n",
      "hour_13\n",
      "Does not require AED    29656\n",
      "Requires AED              117\n",
      "Maybe requires AED         37\n",
      "Name: count, dtype: int64\n",
      "hour_14\n",
      "Does not require AED    15604\n",
      "Name: count, dtype: int64\n",
      "hour_14\n",
      "Does not require AED    29652\n",
      "Requires AED              121\n",
      "Maybe requires AED         37\n",
      "Name: count, dtype: int64\n",
      "hour_15\n",
      "Does not require AED    15604\n",
      "Name: count, dtype: int64\n",
      "hour_15\n",
      "Does not require AED    29652\n",
      "Requires AED              121\n",
      "Maybe requires AED         37\n",
      "Name: count, dtype: int64\n",
      "hour_16\n",
      "Does not require AED    15604\n",
      "Name: count, dtype: int64\n",
      "hour_16\n",
      "Does not require AED    29651\n",
      "Requires AED              122\n",
      "Maybe requires AED         37\n",
      "Name: count, dtype: int64\n",
      "hour_17\n",
      "Does not require AED    15604\n",
      "Name: count, dtype: int64\n",
      "hour_17\n",
      "Does not require AED    29650\n",
      "Requires AED              122\n",
      "Maybe requires AED         38\n",
      "Name: count, dtype: int64\n",
      "hour_18\n",
      "Does not require AED    15604\n",
      "Name: count, dtype: int64\n",
      "hour_18\n",
      "Does not require AED    29649\n",
      "Requires AED              123\n",
      "Maybe requires AED         38\n",
      "Name: count, dtype: int64\n",
      "hour_19\n",
      "Does not require AED    15604\n",
      "Name: count, dtype: int64\n",
      "hour_19\n",
      "Does not require AED    29648\n",
      "Requires AED              124\n",
      "Maybe requires AED         38\n",
      "Name: count, dtype: int64\n",
      "hour_20\n",
      "Does not require AED    15604\n",
      "Name: count, dtype: int64\n",
      "hour_20\n",
      "Does not require AED    29648\n",
      "Requires AED              124\n",
      "Maybe requires AED         38\n",
      "Name: count, dtype: int64\n",
      "hour_21\n",
      "Does not require AED    15604\n",
      "Name: count, dtype: int64\n",
      "hour_21\n",
      "Does not require AED    29647\n",
      "Requires AED              124\n",
      "Maybe requires AED         39\n",
      "Name: count, dtype: int64\n",
      "hour_22\n",
      "Does not require AED    15604\n",
      "Name: count, dtype: int64\n",
      "hour_22\n",
      "Does not require AED    29645\n",
      "Requires AED              126\n",
      "Maybe requires AED         39\n",
      "Name: count, dtype: int64\n",
      "hour_23\n",
      "Does not require AED    15603\n",
      "Maybe requires AED          1\n",
      "Name: count, dtype: int64\n",
      "hour_23\n",
      "Does not require AED    29645\n",
      "Requires AED              126\n",
      "Maybe requires AED         39\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for i in range(24):\n",
    "    column_name= f'hour_{i}'\n",
    "    print(all_predictions['Li√®ge']['Monday'][column_name].value_counts())\n",
    "    print(all_predictions['Charleroi']['Friday'][column_name].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dic_all_predictions500.pkl', 'wb') as f:\n",
    "    pickle.dump(all_predictions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('optimal_knn_model500.pkl', 'wb') as f:\n",
    "    pickle.dump(knn_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'MachineLearning' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimal_knn_model500.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 2\u001b[0m     loaded_knn_model \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute 'MachineLearning' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "#with open('optimal_knn_model500.pkl', 'rb') as f:\n",
    "    #loaded_knn_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('dic_all_predictions.pkl', 'rb') as f:\n",
    "    #loaded_all_predictions = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(1):\n",
    "    #column_name= f'hour_{i}'\n",
    "    #print(loaded_all_predictions['Brussels']['Sunday'][column_name].value_counts())\n",
    "    #print(loaded_all_predictions['Arlon']['Friday'][column_name].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
