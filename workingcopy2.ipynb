{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "from dash import dcc\n",
    "import dash\n",
    "from dash import html\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.graph_objs as go\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import folium\n",
    "from folium.utilities import JsCode\n",
    "from folium.features import GeoJsonPopup\n",
    "from folium.plugins import TimeSliderChoropleth\n",
    "import branca\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              daysofweek  opening_hour  closing_hour  \\\n",
      "0                               [Sunday]             7            17   \n",
      "1  [Thursday, Wednesday, Monday, Friday]             8            20   \n",
      "2                             [Saturday]             8            18   \n",
      "3              [Tuesday, Monday, Sunday]             7            17   \n",
      "4                               [Sunday]             8            19   \n",
      "\n",
      "    opacity   Latitude  Longitude aed_placement  buffer_distance  id  \\\n",
      "0  0.763139  50.894709   3.078928        inside              150   0   \n",
      "1  0.615854  50.673781   4.976167        inside              150   1   \n",
      "2  0.121289  49.931934   4.764849       outside              200   2   \n",
      "3  0.797758  50.946637   3.796990     difficult              125   3   \n",
      "4  0.114180  49.921270   4.772946        inside              150   4   \n",
      "\n",
      "  color_Monday_0  ... color_Sunday_14 color_Sunday_15 color_Sunday_16  \\\n",
      "0            red  ...           green           green           green   \n",
      "1            red  ...             red             red             red   \n",
      "2            red  ...             red             red             red   \n",
      "3            red  ...           green           green           green   \n",
      "4            red  ...           green           green           green   \n",
      "\n",
      "  color_Sunday_17 color_Sunday_18 color_Sunday_19 color_Sunday_20  \\\n",
      "0           green             red             red             red   \n",
      "1             red             red             red             red   \n",
      "2             red             red             red             red   \n",
      "3           green             red             red             red   \n",
      "4           green           green           green             red   \n",
      "\n",
      "  color_Sunday_21 color_Sunday_22 color_Sunday_23  \n",
      "0             red             red             red  \n",
      "1             red             red             red  \n",
      "2             red             red             red  \n",
      "3             red             red             red  \n",
      "4             red             red             red  \n",
      "\n",
      "[5 rows x 177 columns]\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# Initialize Faker to generate fake data\n",
    "fake = Faker()\n",
    "\n",
    "# Define the number of rows in the dataset\n",
    "num_rows = 15000\n",
    "\n",
    "# Create a DataFrame to store the fake dataset\n",
    "practice_df = pd.DataFrame()\n",
    "\n",
    "# Create opening hour variable\n",
    "opening_hour_range = range(7, 9)\n",
    "opening_hour = np.random.choice(opening_hour_range, size=num_rows)\n",
    "\n",
    "# Create closing hour variable\n",
    "closing_hour_range = range(17, 22)\n",
    "closing_hour = np.random.choice(closing_hour_range, size=num_rows)\n",
    "\n",
    "# Create DaysofWeek variable\n",
    "daysofweek_categories = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "daysofweek = [np.random.choice(daysofweek_categories, size=np.random.randint(1, len(daysofweek_categories) + 1), replace=False) for _ in range(num_rows)]\n",
    "\n",
    "# Add DaysofWeek to DataFrame\n",
    "practice_df['daysofweek'] = daysofweek\n",
    "\n",
    "# Add the opening hour variable to the DataFrame\n",
    "practice_df['opening_hour'] = opening_hour\n",
    "\n",
    "# Add the closing hour variable to the DataFrame\n",
    "practice_df['closing_hour'] = closing_hour\n",
    "\n",
    "# Add opacity variable to data frame\n",
    "practice_df['opacity'] = opacity\n",
    "\n",
    "# Generate aed location variable\n",
    "min_lat, max_lat = 49.9, 51.1  # Latitude boundaries of Belgium\n",
    "min_lon, max_lon = 3, 6    # Longitude boundaries of Belgium\n",
    "practice_df['Latitude'] = np.random.uniform(min_lat, max_lat, size=num_rows)\n",
    "practice_df['Longitude'] = np.random.uniform(min_lon, max_lon, size=num_rows)\n",
    "\n",
    "aed_placement_categories = ['outside', 'inside', 'difficult']\n",
    "aed_placement = np.random.choice(aed_placement_categories, size=num_rows)\n",
    "practice_df['aed_placement'] = aed_placement\n",
    "\n",
    "# Define buffer distances\n",
    "buffer_distances = {\n",
    "    'outside': 200,  # ~200 meters in degrees\n",
    "    'inside': 150,   # ~150 meters in degrees\n",
    "    'difficult': 125  # ~125 meters in degrees\n",
    "}\n",
    "\n",
    "practice_df['buffer_distance'] = practice_df['aed_placement'].map(buffer_distances)\n",
    "\n",
    "# Add unique identifier for each row\n",
    "practice_df['id'] = practice_df.index\n",
    "\n",
    "# Initialize a dictionary to hold all the new columns\n",
    "new_columns_dict = {}\n",
    "\n",
    "# Pre-calculate colors based on all possible combinations of days and hours\n",
    "for day in daysofweek_categories:\n",
    "    for hour in range(24):\n",
    "        column_name = f'color_{day}_{hour}'\n",
    "        condition = (\n",
    "            (practice_df['daysofweek'].apply(lambda x: day in x)) & \n",
    "            (practice_df['opening_hour'] <= hour) & \n",
    "            (practice_df['closing_hour'] >= hour)\n",
    "        )\n",
    "        new_columns_dict[column_name] = np.where(condition, 'green', 'red')\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "color_df = pd.DataFrame(new_columns_dict)\n",
    "\n",
    "# Concatenate the new columns to the original DataFrame in a single operation\n",
    "practice_df = pd.concat([practice_df, color_df], axis=1)\n",
    "\n",
    "# Convert DataFrame to GeoDataFrame\n",
    "practice_gdf = gpd.GeoDataFrame(\n",
    "    practice_df,\n",
    "    geometry=[Point(xy) for xy in zip(practice_df['Longitude'], practice_df['Latitude'])],\n",
    "    crs=\"EPSG:4326\"  # WGS84 coordinate system\n",
    ")\n",
    "\n",
    "def generate_folium_map(selected_day):\n",
    "    m = folium.Map(location=[50.5, 4.3517], zoom_start=8)\n",
    "\n",
    "    styledict = {}\n",
    "\n",
    "    for hour in range(24):\n",
    "        styledict[hour] = {}\n",
    "        for idx, row in practice_df.iterrows():\n",
    "            color_column = f'color_{selected_day}_{hour}'\n",
    "            style_dict = {\n",
    "                'color': str(row[color_column]),\n",
    "                'fillColor': str(row[color_column]),\n",
    "                'fillOpacity': float(row['opacity'])  # Ensure opacity is a float\n",
    "            }\n",
    "            styledict[hour][int(row['id'])] = style_dict\n",
    "    print(f'StyleDict for {selected_day}:', styledict)\n",
    "\n",
    "\n",
    "print(practice_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type ndarray is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m TimeSliderChoropleth(\n\u001b[0;32m----> 2\u001b[0m         data\u001b[38;5;241m=\u001b[39m\u001b[43mpractice_gdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      3\u001b[0m         styledict\u001b[38;5;241m=\u001b[39mstyledict\n\u001b[1;32m      4\u001b[0m     )\u001b[38;5;241m.\u001b[39madd_to(m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m m\u001b[38;5;241m.\u001b[39mget_root()\u001b[38;5;241m.\u001b[39mrender()\n\u001b[1;32m      7\u001b[0m app \u001b[38;5;241m=\u001b[39m dash\u001b[38;5;241m.\u001b[39mDash(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/geopandas/geodataframe.py:833\u001b[0m, in \u001b[0;36mGeoDataFrame.to_json\u001b[0;34m(self, na, show_bbox, drop_id, to_wgs84, **kwargs)\u001b[0m\n\u001b[1;32m    830\u001b[0m         ogc_crs \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murn:ogc:def:crs:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mauthority\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m::\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m         geo[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcrs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: ogc_crs}}\n\u001b[0;32m--> 833\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/json/__init__.py:231\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# cached encoder\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m skipkeys \u001b[38;5;129;01mand\u001b[39;00m ensure_ascii \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     check_circular \u001b[38;5;129;01mand\u001b[39;00m allow_nan \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m separators \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sort_keys \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/json/encoder.py:199\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    201\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/json/encoder.py:257\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     _iterencode \u001b[38;5;241m=\u001b[39m _make_iterencode(\n\u001b[1;32m    254\u001b[0m         markers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault, _encoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent, floatstr,\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_keys,\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/json/encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    180\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type ndarray is not JSON serializable"
     ]
    }
   ],
   "source": [
    "TimeSliderChoropleth(\n",
    "        data=practice_gdf.set_index('id').to_json(),\n",
    "        styledict=styledict\n",
    "    ).add_to(m)\n",
    "return m.get_root().render()\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    dcc.RadioItems(\n",
    "        id='day-radioitems',\n",
    "        options=[{'label': day, 'value': day} for day in daysofweek_categories],\n",
    "        value='Monday',\n",
    "        inline=True\n",
    "    ),\n",
    "    html.Iframe(\n",
    "        id='folium-map',\n",
    "        srcDoc=generate_folium_map('Monday'),\n",
    "        width='100%',\n",
    "        height='600px'\n",
    "    )\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    Output('folium-map', 'srcDoc'),\n",
    "    [Input('day-radioitems', 'value')]\n",
    ")\n",
    "def update_map(selected_day):\n",
    "    return generate_folium_map(selected_day)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
